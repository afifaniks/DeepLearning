{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadintg Data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                   (0.5, 0.5, 0.5)),])\n",
    "\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78487ef908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# for i in images:\n",
    "#     plt.imshow(i.numpy().squeeze(), cmap=\"Greys_r\")\n",
    "#     plt.k\n",
    "\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(images.shape)\n",
    "\n",
    "inputs = images.reshape(images.shape[0], -1) # confused bout this line????\n",
    "print(inputs.shape)\n",
    "# Parameters\n",
    "\n",
    "n_input = 784\n",
    "n_hidden_layer = 256\n",
    "n_outputs = 10\n",
    "\n",
    "w1 = torch.randn(n_input, n_hidden_layer)\n",
    "w2 = torch.randn(n_hidden_layer, n_outputs)\n",
    "\n",
    "b1 = torch.randn(n_hidden_layer)\n",
    "b2 = torch.randn(n_outputs)\n",
    "\n",
    "hidden_layer = sigmoid(torch.add(torch.mm(inputs, w1), b1))\n",
    "\n",
    "output_layer = sigmoid(torch.add(torch.mm(hidden_layer, w2), b2))\n",
    "\n",
    "output_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # print(torch.exp(x))\n",
    "    # print(torch.sum(torch.exp(x), dim=1).view(-1, 1))\n",
    "    \n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view((-1, 1))\n",
    "\n",
    "probabilities = softmax(output_layer)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReLU' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac071b57be4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-ac071b57be4c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installs/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installs/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installs/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \"\"\"\n\u001b[0;32m-> 1350\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installs/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReLU' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layer_1 = nn.Linear(784, 128)\n",
    "        self.hidden_layer_2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer_1(x)\n",
    "        x = nn.ReLU(x)\n",
    "        \n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = nn.ReLU(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        x = nn.Softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
